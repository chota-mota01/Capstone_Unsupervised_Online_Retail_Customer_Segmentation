{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "mDgbUHAGgjLW",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bamQiAODYuh1",
        "g-ATYxFrGrvw",
        "yLjJCtPM0KBk",
        "eDbGBLgNi-U4",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chota-mota01/Capstone_Unsupervised_Online_Retail_Customer_Segmentation/blob/main/Online_Retail_Customer_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **Online Retail Customer Segmentation**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project centered around analyzing transactional data from a UK-based non-store online retail company specializing in unique all-occasion gifts. With the goal of identifying distinct customer segments, we embarked on a comprehensive analysis employing RFM (Recency, Frequency, Monetary) analysis and clustering techniques.\n",
        "\n",
        "Initially, the dataset underwent meticulous preprocessing steps, including handling null values, duplicates, and converting the 'InvoiceDate' column to datetime format. These preparatory measures ensured data integrity and facilitated subsequent analysis. For data visualization, the researcher used the seaborn and matplotlib libraries and various types of graphs, such as bar charts, distplot, scatter plots, count plots, correlation heatmaps, and pair plots. These visualizations helped to simplify complex data and make it more understandable. The United Kingdom leads in transaction count, with Thursdays and November showing the highest activity. Transactions peak at 12 pm, with afternoons being the busiest for product sales.\n",
        "\n",
        "RFM analysis played a pivotal role in segmenting customers based on their transactional behavior. By categorizing customers into segments such as high-value, loyal, at-risk, and dormant, we gained valuable insights into their purchasing patterns and engagement levels. This segmentation laid the foundation for targeted marketing strategies and personalized offerings tailored to each customer segment's preferences and needs.\n",
        "\n",
        "In parallel, we employed clustering algorithms to further delineate customer segments and determine the optimal number of clusters. Through methods like K-Means with silhouette score, K-Means with elbow method, and agglomerative clustering, we identified clear segmentation among customers, with an optimal number of clusters determined to be 2. This finding provided actionable insights into customer behavior and preferences, enabling businesses to refine their marketing initiatives and operational strategies effectively.\n",
        "\n",
        "In summary, the project underscored the significance of data-driven approaches in understanding customer dynamics and driving business growth. By leveraging RFM analysis and clustering techniques, businesses can unlock valuable insights, optimize customer engagement strategies, and foster long-term relationships with their customer base, ultimately leading to enhanced customer satisfaction and sustainable business success."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/chota-mota01/Capstone_Unsupervised_Online_Retail_Customer_Segmentation"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The objective of this project is to segment customers based on a transnational dataset that includes all transactions between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail. The company specializes in selling unique all-occasion gifts, with a significant portion of its customer base consisting of wholesalers. The goal is to identify distinct customer segments within the dataset to better understand customer behavior and tailor marketing strategies accordingly."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from numpy import math\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import warnings\n",
        "from pylab import rcParams\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading Data\n",
        "path = '/content/drive/My Drive/Colab Notebooks/Online Retail.xlsx'\n",
        "cus_data = pd.read_excel(path)"
      ],
      "metadata": {
        "id": "nd5r_CbtqvrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "# head() method returns first 5 rows of the dataset\n",
        "cus_data.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If number is specified, head() returns specified number of first rows\n",
        "cus_data.head(3)"
      ],
      "metadata": {
        "id": "nGhEQWPoswxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Last Look\n",
        "# tail() method returns last 5 rows of the dataset\n",
        "cus_data.tail()"
      ],
      "metadata": {
        "id": "HCS-Z5oxsll0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If number is specified, tail() returns specified number of last rows\n",
        "cus_data.tail(3)"
      ],
      "metadata": {
        "id": "AyVZ3l8kssBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "cus_data.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "cus_data.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns present in the dataset\n",
        "list(cus_data.columns)"
      ],
      "metadata": {
        "id": "6l0rO64dtO7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "cus_data.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "cus_data.isna().sum().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "cus_data.isnull().sum()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Check Null value by plotting Heatmap\n",
        "from pickle import FALSE\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.heatmap(cus_data.isnull(),cbar=FALSE)"
      ],
      "metadata": {
        "id": "gGRC6_ntC4DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The transnational dataset includes all transactions between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail. We need to analyze the important factors in the dataset for customer segmentation.\n",
        "\n",
        "The dataset has 541909 rows and 8 columns. The dataset contains 136534 missing/null values and 5268 duplicate values. The null values in column 'Description' and 'CustomerID' are 1454 and 135080 respectively.\n",
        "\n",
        "Using seaborn library, we have visualized the following missing/null values."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "cus_data.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "cus_data.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **InvoiceNo :** 6-digit integral number uniquely assigned to each transaction where starting letter 'c' indicates a cancellation. (Nominal)\n",
        "\n",
        "* **StockCode :** 5-digit integral number uniquely assigned to each distinct product.(Nominal)\n",
        "\n",
        "* **Description :** Item name(Nominal)\n",
        "\n",
        "* **Quantity :** Quantities of each item per transaction (Numeric)\n",
        "\n",
        "* **InvoiceDate :** The day and time when each transaction was generated (Numeric)\n",
        "\n",
        "* **UnitPrice :** Product price per unit in sterling (Numeric)\n",
        "\n",
        "* **CustomerID :** a 5-digit integral number uniquely assigned to each customer(Nominal)\n",
        "\n",
        "* **Country :** Name of the country where each customer resides(Nominal)"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for column in cus_data:\n",
        "  print(cus_data[column].unique())"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count of Unique Values for each variable.\n",
        "for col in cus_data:\n",
        "  print(\"Count of unique values in\",col,\"is\",cus_data[col].nunique(),\".\")"
      ],
      "metadata": {
        "id": "xnIN8In_csk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Create copy of the dataset\n",
        "cus_df = cus_data.copy()\n",
        "cus_df.columns"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop Null values\n",
        "cus_df.dropna(inplace=True)\n",
        "cus_df.info()"
      ],
      "metadata": {
        "id": "7YRVPbptfDgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop InvoiceNo starting with 'c' (cancellation)\n",
        "cus_df['InvoiceNo'] = cus_df['InvoiceNo'].astype('str')"
      ],
      "metadata": {
        "id": "0oYAkj5dg8G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cus_df = cus_df[~cus_df['InvoiceNo'].str.contains('C')]"
      ],
      "metadata": {
        "id": "T6fo-97nlL_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Duplicates\n",
        "cus_df[cus_df.duplicated()==True].head()"
      ],
      "metadata": {
        "id": "SyrJkwykrQXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop Duplicates\n",
        "cus_df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "yZS-34pDrUWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recheck Duplicate Sum\n",
        "cus_df.duplicated().sum()"
      ],
      "metadata": {
        "id": "YO7MMe11rzys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cus_df.shape"
      ],
      "metadata": {
        "id": "okTOJVwbl0gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cus_df.describe()"
      ],
      "metadata": {
        "id": "NsLx_EF8mCjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit price more than 0\n",
        "cus_df= cus_df[cus_df['UnitPrice']>0]"
      ],
      "metadata": {
        "id": "pNH-lQhYCEKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cus_df[\"InvoiceDate\"] = pd.to_datetime(cus_df[\"InvoiceDate\"], format=\"%Y-%m-%d %H:%M:%S\")"
      ],
      "metadata": {
        "id": "sPevYrCXB5Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert InvoiceDate column into date time format\n",
        "cus_df['Day']=cus_df['InvoiceDate'].dt.day_name()"
      ],
      "metadata": {
        "id": "qCDRInh1Caxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new feature from InvoiceDate\n",
        "cus_df[\"year\"] = cus_df[\"InvoiceDate\"].apply(lambda x: x.year)\n",
        "cus_df[\"month_num\"] = cus_df[\"InvoiceDate\"].apply(lambda x: x.month)\n",
        "cus_df[\"day_num\"] = cus_df[\"InvoiceDate\"].apply(lambda x: x.day)\n",
        "cus_df[\"hour\"] = cus_df[\"InvoiceDate\"].apply(lambda x: x.hour)\n",
        "cus_df[\"minute\"] = cus_df[\"InvoiceDate\"].apply(lambda x: x.minute)#"
      ],
      "metadata": {
        "id": "PdY2lh_fCbZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new feature TotalAmount\n",
        "cus_df['TotalAmount']=cus_df['Quantity']*cus_df['UnitPrice']"
      ],
      "metadata": {
        "id": "xLzHyY7EEIBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cus_df['Month']=cus_df['InvoiceDate'].dt.month_name()"
      ],
      "metadata": {
        "id": "q-2qGTV1ER1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While analyzing dataset, we found many null values and duplicate values. Before manipulation of data, we created a copy of the given dataset because of which the changes made in the duplicate dataset won't affect the original dataset.\n",
        "\n",
        "The null values and duplicates in the dataset were dropped. After dropping values, from 541909 rows 392732 rows were left. We converted the 'InvoiceDate' column into date time format. Also, created some new features for ease of understanding.\n",
        "\n",
        "The manipulations performed are for better visualization of the dataset."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1 - Barplot for Top 5 Stocks"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# Top 5 Stock Code\n",
        "Stcode=cus_df['StockCode'].value_counts().reset_index()\n",
        "Stcode.rename(columns={'index': 'Stock Code'}, inplace=True)\n",
        "Stcode.rename(columns={'StockCode': 'Count'}, inplace=True)\n",
        "Stcode.head()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,7))\n",
        "plt.title('Top 5 Stock')\n",
        "sns.barplot(x='Stock Code',y='Count',data=Stcode[:5],palette='pastel')"
      ],
      "metadata": {
        "id": "YfoVCk246Flv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific chart was choosed because bar graphs are the pictorial representation of data in the form of vertical or horizontal rectangular bars, where the length of bars are proportional to the measure of data. It is fundamental visualization used for comparing different sets of data and shows the relationship between two axes.\n",
        "\n",
        "The specific chart tells us about the top 5 stock code."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight from the chart tells us about the top 5 stock code :85123A, 22423, 85099B, 84879 and 47566."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 - Barplot for Bottom 5 Stocks"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Bottom 5 Stock Name\n",
        "plt.figure(figsize=(12,7))\n",
        "plt.title('Bottom 5 Stock')\n",
        "sns.barplot(x='Stock Code',y='Count',data=Stcode[-5:],palette='deep')"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific chart was choosed because a bar plot is a visualization technique used to display categorical data with rectangular bars. The length of each bar represents the frequency or count of data in each category."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight found from the chart tells us the bottom 5 stock code - 90059A, 20678, 90059D, 90168 and 23843."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3 - Distplot for Quantity Distribution"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "#distribution of Quantity\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.title('Quantity Distribution')\n",
        "sns.distplot(cus_df['Quantity'],color=\"Green\")"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific chart was choosed because distplot, short for \"distribution plot,\" represents the distribution of a univariate dataset. It combines a histogram with a kernel density estimate (KDE) plot, providing a visual summary of the distribution of values in the dataset."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following chart gives us the insight of distribution of quantity.\n",
        "\n"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4 - Distplot for Log Quantity Distribution"
      ],
      "metadata": {
        "id": "6GORmrvZ-gXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# Distribution of Quantity\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.title('Log Quantity Distribution')\n",
        "sns.distplot(np.log(cus_df['Quantity']),color=\"Green\")"
      ],
      "metadata": {
        "id": "S68VO54P-gXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "H1wJHIcg-gXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific chart was choosed because distplot, short for \"distribution plot,\" represents the distribution of a univariate dataset. It combines a histogram with a kernel density estimate (KDE) plot, providing a visual summary of the distribution of values in the dataset."
      ],
      "metadata": {
        "id": "p8KFv9MW-gXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZoHTqID6-gXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight from the quantity distribution can be seen clearly after logarithmic transformation."
      ],
      "metadata": {
        "id": "kZKPKAY8-gXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5 - Barplot for Top 10 Countries for Order"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "# Plot top 10 countries as percentage of total order\n",
        "top_coun = cus_df.Country.value_counts()[0:10]/len(cus_df)*100\n",
        "top_coun=pd.DataFrame(top_coun)\n",
        "top_coun.columns=['Percent of total orders']\n",
        "top_coun"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(data=top_coun,y=top_coun.index,x=top_coun['Percent of total orders'],color='darkmagenta')\n",
        "plt.title('Top 10 Countries for Order')\n",
        "plt.ylabel('Country')\n"
      ],
      "metadata": {
        "id": "rUrK8Cx3zI1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The particular chart was selected because a bar plot is a visualization technique used to display categorical data with rectangular bars. The length of each bar represents the frequency or count of data in each category."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following chart gives us top 10 countries according to orders. United Kingdom holds the topmost position."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 - Distplot for Unit Price Distribution"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.title('Unit Price Distribution')\n",
        "sns.distplot(cus_df['UnitPrice'],color=\"Blue\")"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The particular chart was choosed because distplot, short for \"distribution plot,\" represents the distribution of a univariate dataset. It combines a histogram with a kernel density estimate (KDE) plot, providing a visual summary of the distribution of values in the dataset."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight from the chart tells us that mostly unit price is nearly 0."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 - Barplot for Top 10 Product Name"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# Top 10 Product Name\n",
        "des= cus_df['Description'].value_counts().reset_index()\n",
        "des.rename(columns={'index': 'Description_Name'}, inplace=True)\n",
        "des.rename(columns={'Description': 'Count'}, inplace=True)\n",
        "des.head(10)"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25,12))\n",
        "plt.title('Top 10 Product Name')\n",
        "sns.barplot(x='Description_Name',y='Count',data=des[:10],palette='colorblind')"
      ],
      "metadata": {
        "id": "ACP93euxwj1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar graphs are the pictorial representation of data in the form of vertical or horizontal rectangular bars, where the length of bars are proportional to the measure of data. It is fundamental visualization used for comparing different sets of data and shows the relationship between two axes."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights shows us the top 10 product name."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8 - Barplot for Bottom 5 Product"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "des.tail()"
      ],
      "metadata": {
        "id": "pqq7q2Ugx_qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# Barplot for Bottom 5 Product\n",
        "plt.figure(figsize=(15,6))\n",
        "plt.title('Bottom 5 Product Name')\n",
        "sns.barplot(x='Description_Name',y='Count',data=des[-5:],palette='icefire')"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar graphs are the pictorial representation of data in the form of vertical or horizontal rectangular bars, where the length of bars are proportional to the measure of data. It is fundamental visualization used for comparing different sets of data and shows the relationship between two axes."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following chart represents the bottom 5 product name."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 - Barplot for Days of the Week"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "day_det=cus_df['Day'].value_counts().reset_index()\n",
        "day_det.rename(columns={'index': 'Day_Name'}, inplace=True)\n",
        "day_det.rename(columns={'Day': 'Count'}, inplace=True)\n",
        "day_det"
      ],
      "metadata": {
        "id": "E2w5oXu0EzJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "# Days of the Week\n",
        "plt.figure(figsize=(13,8))\n",
        "plt.title('Days of the Week')\n",
        "sns.barplot(x='Day_Name',y='Count',data=day_det,palette ='rocket_r')"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar graphs are the pictorial representation of data in the form of vertical or horizontal rectangular bars, where the length of bars are proportional to the measure of data. It is fundamental visualization used for comparing different sets of data and shows the relationship between two axes."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following chart represents the count of orders placed on different days of the week. The maximum count is obtained on Thursday."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 - Barplot for Months of the Year"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "month_det=cus_df['Month'].value_counts().reset_index()\n",
        "month_det.rename(columns={'index': 'Month_Name'}, inplace=True)\n",
        "month_det.rename(columns={'Month': 'Count'}, inplace=True)\n",
        "month_det"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "# Months of the Year\n",
        "plt.figure(figsize=(13,8))\n",
        "plt.title('Months of the Year')\n",
        "sns.barplot(x='Month_Name',y='Count',data=month_det, palette ='bright')"
      ],
      "metadata": {
        "id": "MScUAzuiFRph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The particular chart is used because bar graph, also known as a bar chart, is a visual representation of data using rectangular bars. Each bar represents a category, and the height or length of the bar corresponds to the value of that category."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following chart represents the count of orders placed on different months of the year. The maximum count is obtained in the month of November."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 - Barplot for Hour"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hour_det=cus_df['hour'].value_counts().reset_index()\n",
        "hour_det.rename(columns={'index': 'Hour_Name'}, inplace=True)\n",
        "hour_det.rename(columns={'hour': 'Count'}, inplace=True)\n",
        "hour_det"
      ],
      "metadata": {
        "id": "ob4p1gn4Hnzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "# Barplot for Hour\n",
        "plt.figure(figsize=(13,8))\n",
        "plt.title('Hour')\n",
        "sns.barplot(x='Hour_Name',y='Count',data=hour_det,palette='pastel')"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar graph, also known as a bar chart, is a visual representation of data using rectangular bars. Each bar represents a category, and the height or length of the bar corresponds to the value of that category."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following chart represents the count of order per hour. The maximum count is obtained at 12 pm."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 - Barplot for Periods of the Day"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def time_period(time):\n",
        "  if(time==6 or time==7 or time==8 or time==9 or time==10 or time==11):\n",
        "    return 'Morning'\n",
        "  elif(time==12 or time==13 or time==14 or time==15 or time==16 or time==17):\n",
        "    return 'Afternoon'\n",
        "  else:\n",
        "    return 'Evening'"
      ],
      "metadata": {
        "id": "9-8lnTPsILbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cus_df['time_period']=cus_df['hour'].apply(time_period)\n"
      ],
      "metadata": {
        "id": "MMBgY627IO1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.title('Periods of the day')\n",
        "sns.countplot(x='time_period',data=cus_df,palette='muted')"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The countplot represents the counts of the observation present in the categorical variable. It uses the concept of a bar chart for the visual depiction."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights from the chart tells us that the maximum product are sold during afternoon."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize=(20,5))\n",
        "cor = sns.heatmap(cus_df.corr(),annot=True)"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation heatmaps are a type of plot that visualize the strength of relationships between numerical variables. Correlation plots are used to understand which variables are related to each other and the strength of this relationship.\n",
        "\n",
        "I used the correlation heatmap to find correlation between all the variables along with correlation coefficient."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above correlation heatmap, we can see that there is correlation between all the independent variables. Also, the dependent and independent variables are highly correlated."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "# sns.pairplot(cus_df)\n",
        "# plt.show()\n",
        "'''The pairplot for RFM is represented below'''"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pairplot visualizes given data to find the relationship between them where the variables can be continuous or categorical. Pairplot allows us to plot pairwise relationships between variables within a dataset."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pairplot basically plots entire dataframe. Plots between each column take place in pairplot and a big plot is created to compare overall relationship between each column. This creates nice visualization and helps us understand the large amount of data in a single figure."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RFM Analysis**"
      ],
      "metadata": {
        "id": "tjbPF_nMCrBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RFM analysis is a customer segmentation technique used in marketing to categorize customers based on their purchasing behavior. RFM stands for Recency, Frequency, and Monetary Value.\n",
        "\n",
        "Recency, Frequency, and Monetary (RFM) are three key metrics used in RFM analysis to evaluate customer behavior:\n",
        "\n",
        "Recency: Measures how recently a customer made a purchase. It indicates the time elapsed since the customer's last transaction. Customers who made a purchase more recently are considered more engaged and valuable.\n",
        "\n",
        "Frequency: Measures how often a customer makes purchases within a specific period. It indicates the number of transactions made by the customer over time. Customers with higher frequency are typically more loyal and engaged.\n",
        "\n",
        "Monetary: Measures the monetary value of a customer's purchases. It represents the total amount of money spent by the customer on purchases. Customers who spend more are considered higher-value customers.\n",
        "\n",
        "By analyzing these three dimensions, RFM analysis helps businesses identify different customer segments, such as high-value customers, loyal customers, at-risk customers, and dormant customers."
      ],
      "metadata": {
        "id": "opHwlmme_Tch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating RFM Scores\n",
        "# Recency = Latest Date - Last Inovice Data, Frequency = count of invoice no. of transaction(s), Monetary = Sum of Total\n",
        "# Amount for each customer\n",
        "import datetime as dt\n",
        "\n",
        "# Set Latest date 2011-12-10 as last invoice date was 2011-12-09. This is to calculate the number of days from recent purchase\n",
        "Latest_Date = dt.datetime(2011,12,10)\n",
        "\n",
        "#Create RFM Modelling scores for each customer\n",
        "rfm_data = cus_df.groupby('CustomerID').agg({'InvoiceDate': lambda x: (Latest_Date - x.max()).days, 'InvoiceNo': lambda x: len(x), 'TotalAmount': lambda x: x.sum()})\n",
        "\n",
        "#Convert Invoice Date into type int\n",
        "rfm_data['InvoiceDate'] = rfm_data['InvoiceDate'].astype(int)\n",
        "\n",
        "#Rename column names to Recency, Frequency and Monetary\n",
        "rfm_data.rename(columns={'InvoiceDate': 'Recency',\n",
        "                         'InvoiceNo': 'Frequency',\n",
        "                         'TotalAmount': 'Monetary'}, inplace=True)\n",
        "\n",
        "rfm_data.reset_index().head()"
      ],
      "metadata": {
        "id": "8vvYox6KCoVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descriptive Statistics (Recency)\n",
        "rfm_data.Recency.describe()\n"
      ],
      "metadata": {
        "id": "pG97tov_DP6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recency distribution plot\n",
        "import seaborn as sns\n",
        "x = rfm_data['Recency']\n",
        "plt.figure(figsize=(11,6))\n",
        "sns.distplot(x)"
      ],
      "metadata": {
        "id": "iKWP-8aHDddx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descriptive Statistics (Frequency)\n",
        "rfm_data.Frequency.describe()"
      ],
      "metadata": {
        "id": "J27g-fd2DgNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequency distribution plot, taking observations which have frequency less than 1000\n",
        "import seaborn as sns\n",
        "x = rfm_data['Frequency']\n",
        "plt.figure(figsize=(11,6))\n",
        "sns.distplot(x)"
      ],
      "metadata": {
        "id": "xr3fNLR6DlsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descriptive Statistics (Monetary)\n",
        "rfm_data.Monetary.describe()"
      ],
      "metadata": {
        "id": "HblS7_EoDpAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Monateray distribution plot with value less than 10000\n",
        "import seaborn as sns\n",
        "x = rfm_data['Monetary']\n",
        "plt.figure(figsize=(11,6))\n",
        "sns.distplot(x)"
      ],
      "metadata": {
        "id": "VCr2bic2DxHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into four segments using quantiles\n",
        "quantiles = rfm_data.quantile(q=[0.25,0.5,0.75])\n",
        "quantiles = quantiles.to_dict()"
      ],
      "metadata": {
        "id": "xDr--U-ED2w2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantiles"
      ],
      "metadata": {
        "id": "AoF4JR3YD7A3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to create R, F and M segments\n",
        "def RScoring(x,p,d):\n",
        "    if x <= d[p][0.25]:\n",
        "        return 1\n",
        "    elif x <= d[p][0.50]:\n",
        "        return 2\n",
        "    elif x <= d[p][0.75]:\n",
        "        return 3\n",
        "    else:\n",
        "        return 4\n",
        "\n",
        "def FnMScoring(x,p,d):\n",
        "    if x <= d[p][0.25]:\n",
        "        return 4\n",
        "    elif x <= d[p][0.50]:\n",
        "        return 3\n",
        "    elif x <= d[p][0.75]:\n",
        "        return 2\n",
        "    else:\n",
        "        return 1\n"
      ],
      "metadata": {
        "id": "rcvXZN4wEO5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Add R, F and M segment value columns\n",
        "rfm_data['R'] = rfm_data['Recency'].apply(RScoring, args=('Recency',quantiles,))\n",
        "rfm_data['F'] = rfm_data['Frequency'].apply(FnMScoring, args=('Frequency',quantiles,))\n",
        "rfm_data['M'] = rfm_data['Monetary'].apply(FnMScoring, args=('Monetary',quantiles,))\n",
        "rfm_data.head()"
      ],
      "metadata": {
        "id": "i0Q0aidIEWED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and Add RFMGroup value column showing combined concatenated score of RFM\n",
        "rfm_data['RFMGroup'] = rfm_data.R.map(str) +rfm_data.F.map(str) + rfm_data.M.map(str)\n",
        "\n",
        "# Calculate and Add RFMScore value column showing total sum of RFMGroup values\n",
        "rfm_data['RFMScore'] = rfm_data[['R', 'F', 'M']].sum(axis = 1)\n",
        "rfm_data.head()"
      ],
      "metadata": {
        "id": "UwncBlsVEk_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle negative and zero values to handle infinite numbers during log transformation\n",
        "def handle_neg_n_zero(num):\n",
        "    if num <= 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return num\n",
        "# Apply handle_neg_n_zero function\n",
        "rfm_data['Recency'] = [handle_neg_n_zero(x) for x in rfm_data.Recency]\n",
        "rfm_data['Monetary'] = [handle_neg_n_zero(x) for x in rfm_data.Monetary]\n",
        "\n",
        "# Perform Log transformation to bring data into near normal distribution\n",
        "Log_Tfd = rfm_data[['Recency', 'Frequency', 'Monetary']].apply(np.log, axis = 1).round(3)\n",
        "\n"
      ],
      "metadata": {
        "id": "QyvBnaAiEu7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data distribution after data normalization for Recency\n",
        "Recency_Plot = Log_Tfd['Recency']\n",
        "plt.figure(figsize=(11,6))\n",
        "sns.distplot(Recency_Plot)"
      ],
      "metadata": {
        "id": "YvxP9NTUE92o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data distribution after data normalization for Frequency\n",
        "Frequency_Plot = Log_Tfd.query('Frequency < 1000')['Frequency']\n",
        "plt.figure(figsize=(11,6))\n",
        "sns.distplot(Frequency_Plot)"
      ],
      "metadata": {
        "id": "bO22UWPjFMZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data distribution after data normalization for Monetary\n",
        "Monetary_Plot = Log_Tfd.query('Monetary < 10000')['Monetary']\n",
        "plt.figure(figsize=(11,6))\n",
        "sns.distplot(Monetary_Plot)"
      ],
      "metadata": {
        "id": "rjCp8cuRFOgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_data['Recency_log'] = rfm_data['Recency'].apply(math.log)\n",
        "rfm_data['Frequency_log'] = rfm_data['Frequency'].apply(math.log)\n",
        "rfm_data['Monetary_log'] = rfm_data['Monetary'].apply(math.log)"
      ],
      "metadata": {
        "id": "58ouck2YFTDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define two hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statement 1 - Recent customers tend to spend more than old customers.\n",
        "\n",
        "Statement 2 - Frequent customers spend more than non-frequent customers."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recent customers tend to spend more than old customers\n",
        "\n",
        "Null hypothesis(H0) : Recent customers do not tend to spend more than old customers.\n",
        "\n",
        "Alternative hypothesis(H1) : Recent customers tend to spend more than old customers."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# create two groups: recent (made a purchase within the last 30 days) and older (made a purchase more than 30 days ago)\n",
        "recent = rfm_data[rfm_data['Recency'] <= 30]\n",
        "older = rfm_data[rfm_data['Recency'] > 30]\n",
        "\n",
        "# calculate mean monetary value for each group\n",
        "mean_recent = np.mean(recent['Monetary'])\n",
        "mean_older = np.mean(older['Monetary'])\n",
        "\n",
        "# state the null hypothesis and alternative hypothesis\n",
        "null_hypothesis = \"Recent customers do not tend to have a higher monetary value than older customers\"\n",
        "alternative_hypothesis = \"Recent customers tend to have a higher monetary value than older customers\"\n",
        "\n",
        "# perform two-sample t-test\n",
        "t, p = ttest_ind(recent['Monetary'], older['Monetary'], equal_var=True)\n",
        "\n",
        "# determine whether to reject the null hypothesis based on the p-value\n",
        "alpha = 0.05\n",
        "if p < alpha:\n",
        "    print(\"Reject the null hypothesis. \" + alternative_hypothesis)\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. \" + null_hypothesis)\n",
        "\n",
        "# output the mean monetary value for each group, as well as the t-statistic and p-value\n",
        "print(\"Mean monetary value of recent customers: \", mean_recent)\n",
        "print(\"Mean monetary value of non-recent customers: \", mean_older)\n",
        "print(\"T-statistic: \", t)\n",
        "print(\"P-value: \", p)\n",
        "print(\"Degrees of freedom: \", len(recent) + len(older) - 2)"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used two sample t-test ."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A two-sample t-test is a statistical hypothesis test used to determine if there is a significant difference between the means of two independent groups."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frequent customers spend more than non-frequent customers.\n",
        "\n",
        "Null hypothesis(H0): Frequent customers do not spend more than non-frequent customers.\n",
        "\n",
        "Alternative hypothesis(H1): Frequent customers spend more than non-frequent customers."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# create two groups: frequent (made more than 10 purchases) and non-frequent (made 10 or fewer purchases)\n",
        "frequent = rfm_data[rfm_data['Frequency'] > 10]\n",
        "non_frequent = rfm_data[rfm_data['Frequency'] <= 10]\n",
        "\n",
        "# calculate mean monetary value for each group\n",
        "mean_frequent = np.mean(frequent['Monetary'])\n",
        "mean_non_frequent = np.mean(non_frequent['Monetary'])\n",
        "\n",
        "# state the null hypothesis and alternative hypothesis\n",
        "null_hypothesis = \"Frequent customers do not spend more than non-frequent customers\"\n",
        "alternative_hypothesis = \"Frequent customers spend more than non-frequent customers\"\n",
        "\n",
        "# perform two-sample t-test\n",
        "t, p = ttest_ind(frequent['Monetary'], non_frequent['Monetary'], equal_var=True)\n",
        "\n",
        "# determine whether to reject the null hypothesis based on the p-value\n",
        "alpha = 0.05\n",
        "if p < alpha:\n",
        "    print(\"Reject the null hypothesis. \" + alternative_hypothesis)\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. \" + null_hypothesis)\n",
        "\n",
        "# output the mean monetary value for each group, as well as the t-statistic and p-value\n",
        "print(\"Mean monetary value of frequent customers: \", mean_frequent)\n",
        "print(\"Mean monetary value of non-frequent customers: \", mean_non_frequent)\n",
        "print(\"Standard deviation of monetary value for frequent customers: \", np.std(frequent['Monetary']))\n",
        "print(\"Standard deviation of monetary value for non-frequent customers: \", np.std(non_frequent['Monetary']))\n",
        "print(\"T-statistic: \", t)\n",
        "print(\"P-value: \", p)\n",
        "print(\"Degrees of freedom: \", len(frequent) + len(non_frequent) - 2)"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used two sample t-test."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A two-sample t-test is a statistical hypothesis test used to determine if there is a significant difference between the means of two independent groups."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot heatmap of the feature correlations in the dataframe\n",
        "sns.heatmap(rfm_data.corr(), annot=True, cmap='Reds')"
      ],
      "metadata": {
        "id": "us1ndBfWM4kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pairplot using Seaborn.\n",
        "sns.pairplot(rfm_data, diag_kind='kde')"
      ],
      "metadata": {
        "id": "HBkx95cTNBnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "''' The null values from the given dataset was dropped during Data Manipulation'''"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "'''Log transformation was used '''"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "'''Created new features in data manipulation section'''"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 - K-Means Clustering with Silhouette Method"
      ],
      "metadata": {
        "id": "eDbGBLgNi-U4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Means clustering is a popular unsupervised machine learning algorithm used for partitioning data into K distinct clusters. The Silhouette method is a technique used to evaluate the quality of clustering by measuring how well-separated the clusters are."
      ],
      "metadata": {
        "id": "DHahHIBdHiJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "# Applying Silhouette Method on Recency , Frequency and Monetary\n",
        "feature_vector=['Recency_log','Frequency_log','Monetary_log']\n",
        "X_features=rfm_data[feature_vector].values\n",
        "scaler=preprocessing.StandardScaler()\n",
        "X=scaler.fit_transform(X_features)\n"
      ],
      "metadata": {
        "id": "XefuAFF-i-U4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "range_n_clusters = [2,3,4,5,6]\n",
        "\n",
        "for n_clusters in range_n_clusters:\n",
        "    # Create a subplot with 1 row and 2 columns\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.set_size_inches(18, 7)\n",
        "\n",
        "    # The 1st subplot is the silhouette plot\n",
        "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
        "    # lie within [-0.1, 1]\n",
        "    ax1.set_xlim([-0.1, 1])\n",
        "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
        "    # plots of individual clusters, to demarcate them clearly.\n",
        "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
        "\n",
        "    # Initialize the clusterer with n_clusters value and a random generator\n",
        "    # seed of 10 for reproducibility.\n",
        "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
        "    cluster_labels = clusterer.fit_predict(X)\n",
        "\n",
        "    # The silhouette_score gives the average value for all the samples.\n",
        "    # This gives a perspective into the density and separation of the formed\n",
        "    # clusters\n",
        "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "    print(\"For n_clusters =\", n_clusters,\n",
        "          \"The average silhouette_score is :\", silhouette_avg)\n",
        "\n",
        "    # Compute the silhouette scores for each sample\n",
        "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
        "\n",
        "    y_lower = 10\n",
        "    for i in range(n_clusters):\n",
        "        # Aggregate the silhouette scores for samples belonging to\n",
        "        # cluster i, and sort them\n",
        "        ith_cluster_silhouette_values = \\\n",
        "            sample_silhouette_values[cluster_labels == i]\n",
        "\n",
        "        ith_cluster_silhouette_values.sort()\n",
        "\n",
        "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "\n",
        "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
        "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
        "                          0, ith_cluster_silhouette_values,\n",
        "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
        "\n",
        "        # Label the silhouette plots with their cluster numbers at the middle\n",
        "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "\n",
        "        # Compute the new y_lower for next plot\n",
        "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
        "\n",
        "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
        "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
        "    ax1.set_ylabel(\"Cluster label\")\n",
        "\n",
        "    # The vertical line for average silhouette score of all the values\n",
        "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
        "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "\n",
        "    # 2nd Plot showing the actual clusters formed\n",
        "    colors = cm.nipy_spectral(cluster_labels.astype(float) /n_clusters)\n",
        "    ax2.scatter(X[:, 0], X[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
        "                c=colors, edgecolor='k')\n",
        "\n",
        "    # Labeling the clusters\n",
        "    centers = clusterer.cluster_centers_\n",
        "    # Draw white circles at cluster centers\n",
        "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
        "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
        "\n",
        "    for i, c in enumerate(centers):\n",
        "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
        "                    s=50, edgecolor='k')\n",
        "\n",
        "    ax2.set_title(\"The visualization of the clustered data.\")\n",
        "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
        "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
        "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
        "                  \"with n_clusters = %d\" % n_clusters),\n",
        "                 fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GMiKaRgrjVYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "6Vi39YmYi-U5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans(n_clusters=2)\n",
        "kmeans.fit(X)\n",
        "y_kmeans= kmeans.predict(X)\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.title('customer segmentation based on    Recency ,Frequency and Monetary')\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='RdYlBu')\n",
        "\n",
        "centers = kmeans.cluster_centers_\n",
        "plt.scatter(centers[:, 0], centers[:, 1], c='yellow', s=200, alpha=0.5)"
      ],
      "metadata": {
        "id": "U3F5V31fi-U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scatter plot is a widely utilized visualization tool to depict the distribution of data points across a two-dimensional space. In this context, it serves to illustrate customer segmentation derived from RFM (Recency, Frequency, Monetary) features.\n",
        "\n",
        "When clustering customers based on their Recency, Frequency, and Monetary (RFM) metrics, distinct clusters emerge, indicating clear segmentation among customers."
      ],
      "metadata": {
        "id": "le2irnQ_RoUP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 - K-Means Clustering with Elbow Method"
      ],
      "metadata": {
        "id": "iBOJ_u3igqgo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The K-Means clustering algorithm is widely used for partitioning a dataset into a predetermined number of clusters. The Elbow method is a technique used to find the optimal number of clusters by plotting the within-cluster sum of squared distances (WCSS) against the number of clusters."
      ],
      "metadata": {
        "id": "-gg9IDqoIcCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "# Applying Elbow Method on Recency , Frequency and Monetary\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "sum_of_sq_dist = {}\n",
        "for k in range(1,15):\n",
        "    km = KMeans(n_clusters= k, init= 'k-means++', max_iter= 1000)\n",
        "    km = km.fit(X)\n",
        "    sum_of_sq_dist[k] = km.inertia_\n",
        "\n",
        "#Plot the graph for the sum of square distance values and Number of Clusters\n",
        "sns.pointplot(x = list(sum_of_sq_dist.keys()), y = list(sum_of_sq_dist.values()))\n",
        "plt.xlabel('Number of Clusters(k)')\n",
        "plt.ylabel('Sum of Square Distances')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yybLS9l3gqgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform K-Mean Clustering or build the K-Means clustering model\n",
        "KMean_clust = KMeans(n_clusters= 2, init= 'k-means++', max_iter= 1000)\n",
        "KMean_clust.fit(X)\n",
        "\n",
        "#Find the clusters for the observation given in the dataset\n",
        "rfm_data['Cluster'] = KMean_clust.labels_\n",
        "rfm_data.head(10)"
      ],
      "metadata": {
        "id": "O4re5q_Gh8C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the dendogram to find the optimal number of clusters\n",
        "import scipy.cluster.hierarchy as sch\n",
        "plt.figure(figsize=(13,8))\n",
        "dendrogram = sch.dendrogram(sch.linkage(X, method = 'ward'))\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Customers')\n",
        "plt.ylabel('Euclidean Distances')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T-lCi0BwiENR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "cMCYRXFugqgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "'''The chart is represented above. The number of clusters corresponds to the count of vertical lines intersected by the threshold line drawn at\n",
        "a value of 90.'''"
      ],
      "metadata": {
        "id": "V_pqihS-gqgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 - Agglomerative Clustering"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agglomerative clustering is a hierarchical clustering technique used to group similar data points into clusters. It starts with each data point as a separate cluster and then merges the closest clusters iteratively until only one cluster remains."
      ],
      "metadata": {
        "id": "z115uoOMJLgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "# Fitting hierarchical clustering to the mall dataset\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "hc = AgglomerativeClustering(n_clusters = 2, affinity = 'euclidean', linkage = 'ward')\n",
        "y_hc = hc.fit_predict(X)\n"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the clusters (two dimensions only)\n",
        "plt.figure(figsize=(13,8))\n",
        "plt.scatter(X[y_hc == 0, 0], X[y_hc == 0, 1], s = 100, c = 'red', label = 'Customer 1')\n",
        "plt.scatter(X[y_hc == 1, 0], X[y_hc == 1, 1], s = 100, c = 'blue', label = 'Customer 2')\n",
        "#plt.scatter(X[y_hc == 2, 0], X[y_hc == 2, 1], s = 100, c = 'green', label = 'Target')\n",
        "\n",
        "plt.title('Clusters of Customer')\n",
        "plt.xlabel('RFM')\n",
        "\n",
        "plt.ylabel('Spending Score (1-100)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RWu14ymFicJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "# Specify the Column Names while initializing the Table\n",
        "myTable = PrettyTable(['SL No.',\"Model_Name\",'Data', \"Optimal_Number_of_cluster\"])\n",
        "\n",
        "# Add rows\n",
        "myTable.add_row(['1',\"K-Means with silhouette_score \", \"RFM\", \"2\"])\n",
        "myTable.add_row(['2',\"K-Means with Elbow methos  \", \"RFM\", \"2\"])\n",
        "myTable.add_row(['3',\"Agglomerative clustering  \", \"RFM\", \"2\"])\n",
        "print(myTable)"
      ],
      "metadata": {
        "id": "8iFBF402UN5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RFM analysis helps businesses identify different customer segments, such as high-value customers, loyal customers, at-risk customers, and dormant customers. This segmentation enables businesses to tailor their marketing strategies and offerings to better meet the needs of each customer segment, thereby improving customer satisfaction and driving revenue growth. By applying various clustering algorithms to our dataset, we determined that the optimal number of clusters is 2."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After conducting various clustering methods, including K-Means with silhouette score, K-Means with the elbow method, and agglomerative clustering, we concluded that the optimal number of clusters for our dataset is 2. Among these methods, we found that K-Means clustering with the silhouette score is the most straightforward and effective approach.\n",
        "\n",
        "The silhouette score method measures the quality of clustering based on the average distance between data points within the same cluster and the average distance between data points in different clusters. A higher silhouette score indicates better-defined clusters. In our case, the silhouette score analysis indicated that 2 clusters provided the most cohesive grouping of data points.\n",
        "\n",
        "By leveraging K-Means clustering with the silhouette score, we can easily segment our dataset into two distinct clusters, allowing for clear differentiation between customer groups. This approach simplifies the clustering process and facilitates the interpretation of results, making it a practical choice for our analysis."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The objective of this project is to segment customers based on a transnational dataset that includes all transactions between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail. To ensure the integrity of the original dataset, we created a duplicate copy for subsequent manipulations, safeguarding the primary data from unintended alterations. We eliminated both null values and duplicates from the dataset.\n",
        "\n",
        "The United Kingdom emerges as the leading region in terms of transaction count, indicating a strong customer base or market presence in that region. Thursday stands out as the day with the highest transaction count, suggesting heightened activity or sales on that particular day of the week. Moreover, November emerges as the month with the highest transaction count, possibly indicating increased sales activity due to seasonal factors or promotions during that period. Additionally, transactions peak at 12 pm, suggesting a surge in sales activity during the midday hours. Furthermore, the afternoon emerges as the time period with the highest product sales, underscoring the significance of afternoon hours in driving sales volume.\n",
        "\n",
        "In our analysis, we explored three distinct clustering techniques to identify meaningful patterns within the dataset: K-means clustering with the silhouette method, K-means clustering with the elbow method, and agglomerative clustering. Through the application of various clustering algorithms to our dataset, we identified that the optimal number of clusters is 2. This finding underscores the importance of segmentation in understanding customer behavior and preferences. With this knowledge, businesses can effectively allocate resources, tailor marketing initiatives, and optimize operational strategies to maximize customer engagement and retention. The insights gained from RFM analysis and clustering enable businesses to make informed decisions that lead to improved customer experiences and sustainable business success.\n",
        "\n",
        "Each method offers unique insights into the underlying structure of the data and helps us uncover clusters or groups that share similar characteristics. By comparing the results obtained from these different approaches, we can gain a comprehensive understanding of the data and extract valuable insights that can inform decision-making processes."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}